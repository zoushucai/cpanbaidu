import json
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from threading import Lock
from typing import Any, Literal, Optional

from pydantic import validate_call
from .model.Base import UserInfoModel
from .Auth import Auth
from .utils.Constants import API
from .utils.md5 import (
    calculate_md5,
    calculate_slice_md5,
    get_file_md5_blocks,
)


class Upload:
    def __init__(self, auth: Auth):
        """ä¸Šä¼ ç±»
        
        Args:
            auth: Auth ç±»å®ä¾‹
        """
        self.auth = auth

    @validate_call
    def precreate(
        self,
        path: str,
        size: int,
        isdir: Literal[0, 1],
        block_list: list[str] | str,
        rtype: Literal[1, 2, 3] = 1,
        uploadid: Optional[str] = None,
        content_md5: Optional[str] = None,
        slice_md5: Optional[str] = None,
        local_ctime: Optional[int] = None,
        local_mtime: Optional[int] = None,
    ) -> dict[str, Any] | None:
        """é¢„ä¸Šä¼ 

        é¢„ä¸Šä¼ æ˜¯é€šçŸ¥ç½‘ç›˜äº‘ç«¯æ–°å»ºä¸€ä¸ªä¸Šä¼ ä»»åŠ¡, ç½‘ç›˜äº‘ç«¯è¿”å›å”¯ä¸€ID uploadid æ¥æ ‡è¯†æ­¤ä¸Šä¼ ä»»åŠ¡.

        å¯¹åº”ç™¾åº¦çš„APIæ¥å£: [https://pan.baidu.com/union/doc/3ksg0s9r7](https://pan.baidu.com/union/doc/3ksg0s9r7)

        æ³¨æ„äº‹é¡¹:
            æ‰§è¡Œç¤ºä¾‹ä»£ç æ—¶ï¼Œè¯·å°†ç¤ºä¾‹ä»£ç ä¸­çš„access_tokenå‚æ•°å€¼æ›¿æ¢ä¸ºè‡ªè¡Œè·å–çš„access_token
            äº‘ç«¯æ–‡ä»¶é‡å‘½åç­–ç•¥è¯´æ˜ï¼šå½“äº‘ç«¯å·²æœ‰æ–‡ä»¶test.txtæ—¶ï¼Œæ–°çš„æ–‡ä»¶åå­—ä¸ºtest(1).txtï¼›å½“äº‘ç«¯å·²æœ‰ç›®å½• /diræ—¶ï¼Œæ–°çš„ç›®å½•åå­—ä¸º/dir(1)

        Args:
            path: ä¸Šä¼ çš„æ–‡ä»¶æˆ–ç›®å½•çš„è·¯å¾„
            size: æ–‡ä»¶å’Œç›®å½•ä¸¤ç§æƒ…å†µ:ä¸Šä¼ æ–‡ä»¶æ—¶, è¡¨ç¤ºæ–‡ä»¶çš„å¤§å°, å•ä½Bï¼›ä¸Šä¼ ç›®å½•æ—¶, è¡¨ç¤ºç›®å½•çš„å¤§å°, ç›®å½•çš„è¯å¤§å°é»˜è®¤ä¸º0
            isdir: æ˜¯å¦ä¸ºç›®å½•, 0 æ–‡ä»¶, 1 ç›®å½•
            block_list: åˆ†ç‰‡ä¸Šä¼ æ—¶, åˆ†ç‰‡åˆ—è¡¨, åˆ†ç‰‡å¤§å°ä¸º4MB, æœ€å¤§æ”¯æŒ10000ä¸ªåˆ†ç‰‡
            rtype: æ–‡ä»¶å‘½åç­–ç•¥. 1 è¡¨ç¤ºå½“pathå†²çªæ—¶, è¿›è¡Œé‡å‘½å //2 è¡¨ç¤ºå½“pathå†²çªä¸”block_listä¸åŒæ—¶, è¿›è¡Œé‡å‘½å
            uploadid: ä¸Šä¼ ID
            content_md5: æ–‡ä»¶MD5, 32ä½å°å†™
            slice_md5: æ–‡ä»¶æ ¡éªŒæ®µçš„MD5, 32ä½å°å†™, æ ¡éªŒæ®µå¯¹åº”æ–‡ä»¶å‰256KB
            local_ctime: å®¢æˆ·ç«¯åˆ›å»ºæ—¶é—´,  é»˜è®¤ä¸ºå½“å‰æ—¶é—´æˆ³
            local_mtime: å®¢æˆ·ç«¯ä¿®æ”¹æ—¶é—´,  é»˜è®¤ä¸ºå½“å‰æ—¶é—´æˆ³
        """
        # URL å‚æ•°ï¼šåªæœ‰ method
        url_params = {
            "method": "precreate",
        }

        # RequestBody å‚æ•°ï¼šå…¶ä»–æ‰€æœ‰å‚æ•°
        data = {
            "path": path,
            "size": size,
            "isdir": isdir,
            "block_list": json.dumps(block_list, separators=(",", ":")),
            "autoinit": 1,  # å›ºå®šå€¼
            "rtype": rtype,
            "uploadid": uploadid,
            "content-md5": content_md5,
            "slice-md5": slice_md5,
            "local_ctime": local_ctime,
            "local_mtime": local_mtime,
        }

        respjson = self.auth.request_json("POST", API.UploadPath.PRECREATE, params=url_params, data=data)
        return respjson

    @validate_call
    def upload_part(self, url: str, path: str, uploadid: str, partseq: int, files: Any) -> dict[str, Any] | None:
        """åˆ†ç‰‡ä¸Šä¼ 
        æœ¬æ¥å£ç”¨äºå°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°ç½‘ç›˜äº‘ç«¯æœåŠ¡å™¨.


        æ–‡ä»¶åˆ†ä¸¤ç§ç±»å‹:å°æ–‡ä»¶, æ˜¯æŒ‡æ–‡ä»¶å¤§å°å°äºç­‰äº4MBçš„æ–‡ä»¶, æˆåŠŸè°ƒç”¨ä¸€æ¬¡æœ¬æ¥å£å, è¡¨ç¤ºåˆ†ç‰‡ä¸Šä¼ é˜¶æ®µå®Œæˆï¼›å¤§æ–‡ä»¶, æ˜¯æŒ‡æ–‡ä»¶å¤§å°å¤§äº4MBçš„æ–‡ä»¶, éœ€è¦å…ˆå°†æ–‡ä»¶æŒ‰ç…§4MBå¤§å°è¿›è¡Œåˆ‡åˆ†, ç„¶åé’ˆå¯¹åˆ‡åˆ†åçš„åˆ†ç‰‡åˆ—è¡¨, é€ä¸ªåˆ†ç‰‡è¿›è¡Œä¸Šä¼ , åˆ†ç‰‡åˆ—è¡¨çš„åˆ†ç‰‡å…¨éƒ¨æˆåŠŸä¸Šä¼ å, è¡¨ç¤ºåˆ†ç‰‡ä¸Šä¼ é˜¶æ®µå®Œæˆ.

        æ ¹æ®ä¸åŒçš„ç”¨æˆ·ç­‰çº§æœ‰ä¸åŒçš„é™åˆ¶

        å¯¹åº”ç™¾åº¦çš„APIæ¥å£: [https://pan.baidu.com/union/doc/nksg0s9vi](https://pan.baidu.com/union/doc/nksg0s9vi)

        Args:
            url: ä¸Šä¼ åŸŸåï¼ˆä» locateupload æ¥å£è·å–ï¼‰
            path: ä¸Šä¼ çš„æ–‡ä»¶çš„è·¯å¾„
            uploadid: ä¸Šä¼ ID
            partseq: åˆ†ç‰‡åºå·, ä»0å¼€å§‹
            files: ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹

        Returns:
            åˆ†ç‰‡ä¸Šä¼ ç»“æœ
        """

        params = {
            "method": "upload",
            "type": "tmpfile",
            "path": path,
            "uploadid": uploadid,
            "partseq": partseq,
        }

        resp = self.auth.request("POST", url, params=params, files=files)
        return resp.json()

    @validate_call
    def create(
        self,
        path: str,
        size: str,
        isdir: Literal["0", "1"],
        block_list: list[str] | str,
        uploadid: str,
        rtype: Literal[1, 2, 3] = 1,
        local_ctime: Optional[int] = None,
        local_mtime: Optional[int] = None,
        zip_quality: Optional[Literal[50, 70, 100]] = None,
        zip_sign: Optional[int] = None,
        is_revision: Optional[int] = 0,
        mode: Optional[Literal[0, 1, 2, 3, 4, 5]] = None,
        exif_info: Optional[str] = None,
    ) -> dict[str, Any] | None:
        """åˆ›å»ºæ–‡ä»¶

        æœ¬æ¥å£ç”¨äºå°†å¤šä¸ªæ–‡ä»¶åˆ†ç‰‡åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶, ç”Ÿæˆæ–‡ä»¶åŸºæœ¬ä¿¡æ¯, å®Œæˆæ–‡ä»¶çš„ä¸Šä¼ æœ€åä¸€æ­¥.


        å¯¹åº”ç™¾åº¦çš„APIæ¥å£: [https://pan.baidu.com/union/doc/rksg0sa17](https://pan.baidu.com/union/doc/rksg0sa17)

        Args:
            path (str): ä¸Šä¼ çš„æ–‡ä»¶æˆ–ç›®å½•çš„è·¯å¾„
            size (str): æ–‡ä»¶å’Œç›®å½•ä¸¤ç§æƒ…å†µ:ä¸Šä¼ æ–‡ä»¶æ—¶, è¡¨ç¤ºæ–‡ä»¶çš„å¤§å°, å•ä½Bï¼›ä¸Šä¼ ç›®å½•æ—¶, è¡¨ç¤ºç›®å½•çš„å¤§å°, ç›®å½•çš„è¯å¤§å°é»˜è®¤ä¸º0
            isdir (Literal[0, 1]): æ˜¯å¦ä¸ºç›®å½•, 0 æ–‡ä»¶, 1 ç›®å½•
            block_list (list[str] | str):  æ–‡ä»¶å„åˆ†ç‰‡md5æ•°ç»„çš„jsonä¸²
            uploadid (str): é¢„ä¸Šä¼ precreateæ¥å£ä¸‹å‘çš„uploadid
            rtype (Literal[1, 2, 3]): æ–‡ä»¶å‘½åç­–ç•¥.

                - 1 è¡¨ç¤ºå½“pathå†²çªæ—¶, è¿›è¡Œé‡å‘½å
                - 2 è¡¨ç¤ºå½“pathå†²çªä¸”block_listä¸åŒæ—¶, è¿›è¡Œé‡å‘½å
                - 3 ä¸ºè¦†ç›–, éœ€è¦ä¸é¢„ä¸Šä¼ precreateæ¥å£ä¸­çš„rtypeä¿æŒä¸€è‡´
            local_ctime (Optional[int]): å®¢æˆ·ç«¯åˆ›å»ºæ—¶é—´,  é»˜è®¤ä¸ºå½“å‰æ—¶é—´æˆ³
            local_mtime (Optional[int]): å®¢æˆ·ç«¯ä¿®æ”¹æ—¶é—´,  é»˜è®¤ä¸ºå½“å‰æ—¶é—´æˆ³
            zip_quality (Optional[Literal[50, 70, 100]]): å›¾ç‰‡å‹ç¼©ç¨‹åº¦, æœ‰æ•ˆå€¼50ã€70ã€100, (ä¸zip_signä¸€èµ·ä½¿ç”¨)
            zip_sign (Optional[int]): æœªå‹ç¼©åŸå§‹å›¾ç‰‡æ–‡ä»¶çœŸå®md5(ä¸zip_qualityä¸€èµ·ä½¿ç”¨)
            is_revision (Optional[int]): æ˜¯å¦éœ€è¦å¤šç‰ˆæœ¬æ”¯æŒ, 1ä¸ºæ”¯æŒ, 0ä¸ºä¸æ”¯æŒ,  é»˜è®¤ä¸º0 (å¸¦æ­¤å‚æ•°ä¼šå¿½ç•¥é‡å‘½åç­–ç•¥)
            mode (Optional[Literal[0, 1, 2, 3, 4, 5]]): ä¸Šä¼ æ–¹å¼

                - 1 æ‰‹åŠ¨ã€
                - 2 æ‰¹é‡ä¸Šä¼ 
                - 3 æ–‡ä»¶è‡ªåŠ¨å¤‡ä»½
                - 4 ç›¸å†Œè‡ªåŠ¨å¤‡ä»½
                - 5 è§†é¢‘è‡ªåŠ¨å¤‡ä»½
            exif_info (Optional[str]): jsonå­—ç¬¦ä¸², orientationã€widthã€heightã€recoveryä¸ºå¿…ä¼ å­—æ®µ, å…¶ä»–å­—æ®µå¦‚æœæ²¡æœ‰å¯ä»¥ä¸ä¼ 
        """
        # URL å‚æ•°ï¼šåªæœ‰ method
        params = {
            "method": "create",
        }

        # RequestBody å‚æ•°ï¼šå…¶ä»–æ‰€æœ‰å‚æ•°
        data = {
            "path": path,
            "size": size,
            "isdir": isdir,
            "block_list": block_list,
            "uploadid": uploadid,
            "rtype": rtype,
            "local_ctime": local_ctime,
            "local_mtime": local_mtime,
            "zip_quality": zip_quality,
            "zip_sign": zip_sign,
            "is_revision": is_revision,
            "mode": mode,
            "exif_info": exif_info,
        }
        respjson = self.auth.request_json("POST", API.UploadPath.CREATE, params=params, data=data)
        return respjson

    @validate_call
    def upload_simple(
        self,
        url: str,
        path: str,
        file: Any,
        ondup: Literal["newcopy", "overwrite", "fail"] = "newcopy",
    ) -> dict[str, Any] | None:
        """ç®€å•ä¸Šä¼ æ–‡ä»¶

        æœ¬æ¥å£ç”¨äºå°†æœ¬åœ°å°æ–‡ä»¶ä¸Šä¼ åˆ°ç½‘ç›˜äº‘ç«¯æœåŠ¡å™¨.


        å¯¹åº”ç™¾åº¦çš„APIæ¥å£: [https://pan.baidu.com/union/doc/Llvw5hfnm](https://pan.baidu.com/union/doc/Llvw5hfnm)

        Args:
            url: ä¸Šä¼ åŸŸåï¼ˆä» locateupload æ¥å£è·å–ï¼‰
            path: ä¸Šä¼ çš„æ–‡ä»¶ç»å¯¹è·¯å¾„
            ondup: æ–‡ä»¶å†²çªå¤„ç†ç­–ç•¥, ä¸Šä¼ çš„æ–‡ä»¶ç»å¯¹è·¯å¾„å†²çªæ—¶çš„ç­–ç•¥ã€‚

                - fail: ç›´æ¥è¿”å›å¤±è´¥(é»˜è®¤, æ”¹æˆ newcopy)
                - newcopy: é‡å‘½åæ–‡ä»¶
                - overwrite: è¦†ç›–æ–‡ä»¶
            file: ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹


        Returns:
            ç®€å•ä¸Šä¼ ç»“æœ
        """

        params = {
            "method": "upload",
            "path": path,
            "ondup": ondup,
        }

        respjson = self.auth._do_request("POST", url, params=params, files=file).json()

        return respjson

    @validate_call
    def locateupload(
        self,
        path: str,
        uploadid: str,
    ) -> dict[str, Any] | None:
        """è·å–ä¸Šä¼ åŸŸå

        æœ¬æ¥å£ç”¨äºè·å–ä¸Šä¼ åŸŸå.

        ä¸Šä¼ æ–‡ä»¶æ•°æ®æ—¶, éœ€è¦å…ˆé€šè¿‡æ­¤æ¥å£è·å–ä¸Šä¼ åŸŸå. å¯ä½¿ç”¨è¿”å›ç»“æœserverså­—æ®µä¸­çš„ https åè®®çš„ä»»æ„ä¸€ä¸ªåŸŸå.

        å¯¹åº”ç™¾åº¦çš„APIæ¥å£: [https://pan.baidu.com/union/doc/Mlvw5hfnr](https://pan.baidu.com/union/doc/Mlvw5hfnr)

        Args:
            path (str): ä¸Šä¼ åä½¿ç”¨çš„æ–‡ä»¶ç»å¯¹è·¯å¾„
            uploadid (str): ä¸Šä¼ ID

        Returns:
            åŒ…å«ä¸Šä¼ åŸŸåçš„å­—å…¸

        """
        params = {
            "method": "locateupload",
            "appid": 250528,
            "path": path,
            "uploadid": uploadid,
            "upload_version": "2.0",
        }
        respjson = self.auth._do_request("GET", API.UploadPath.LOCATEUPLOAD, params=params).json()
        return respjson


class UploadFile:
    """ä¸Šä¼ æ–‡ä»¶ç±», è´Ÿè´£å°†æœ¬åœ°æ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ åˆ°ç™¾åº¦ç½‘ç›˜.  (ä½¿ç”¨å¤šçº¿ç¨‹ä¸Šä¼ )

    Attributes:
        up (Upload): ä¸Šä¼ å¯¹è±¡çš„å®ä¾‹.

    Example:
    ```python
    from cpanbd import UploadFile, APPNAME

    pan = UploadFile()
    local_filename = "tdata/xxx/Robot0309.zip"
    upload_path = f"/apps/{APPNAME}/tdata/xxx/Robot0309.zip"
    # ä¸Šä¼ æ–‡ä»¶åˆ°ç½‘ç›˜
    pan.upload_file(
        local_filename=local_filename,
        upload_path=upload_path,
        isdir=0,
        rtype=1,
        bs=32,
        show_progress=True,
    )
    # å¦‚æœè¦æ‰¹é‡,åªéœ€è¦å¾ªç¯å³å¯
    ```
    """

    def __init__(self, auth: Auth, userinfo: Optional[UserInfoModel] = None):
        """ä¸Šä¼ æ–‡ä»¶ç±»
        
        Args:
            auth: Auth ç±»å®ä¾‹
            userinfo: ç”¨æˆ·ä¿¡æ¯æ¨¡å‹å®ä¾‹
        
        """
        self.up = Upload(auth)
        self.userinfo = userinfo

    def upload_part(
        self,
        server_url: str,
        upload_path: str,
        uploadid: str,
        idx: int,
        chunk: bytes,
        expected_md5: str,
        progress: dict,
        show_progress: bool = True,
    ) -> int:
        """
        ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ†ç‰‡å¹¶æ›´æ–°ä¸Šä¼ è¿›åº¦.

        Args:
            server_url (str): ä¸Šä¼ æœåŠ¡å™¨çš„ URL.
            upload_path (str): æ–‡ä»¶åœ¨ç½‘ç›˜ä¸­çš„ç›®æ ‡è·¯å¾„.
            uploadid (str): ä¸Šä¼ ä¼šè¯çš„ ID.
            idx (int): å½“å‰åˆ†ç‰‡çš„ç´¢å¼•.
            chunk (bytes): å½“å‰åˆ†ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®.
            expected_md5 (str): å½“å‰åˆ†ç‰‡çš„é¢„æœŸ MD5 å€¼.
            progress (Dict[str, object]): åŒ…å«ä¸Šä¼ è¿›åº¦ä¿¡æ¯çš„å­—å…¸.

        Returns:
            int: æˆåŠŸä¸Šä¼ çš„åˆ†ç‰‡ç´¢å¼•.

        Raises:
            Exception: å¦‚æœä¸Šä¼ å¤±è´¥æˆ– MD5 æ ¡éªŒä¸ä¸€è‡´.
        """
        files = {"file": ("part", chunk)}
        res = self.up.upload_part(
            url=server_url + "/rest/2.0/pcs/superfile2",
            path=upload_path,
            uploadid=uploadid,
            partseq=idx,
            files=files,
        )
        if not res or not res.get("md5"):
            raise Exception(f"ä¸Šä¼ åˆ†ç‰‡å¤±è´¥: {res}")
        if res["md5"] != expected_md5:
            raise Exception(f"åˆ†ç‰‡ {idx} çš„ MD5 ä¸ä¸€è‡´: é¢„æœŸ {expected_md5}, å®é™… {res['md5']}")

        if progress["lock"]:
            progress["uploaded"] += 1
            if show_progress:
                percent = (progress["uploaded"] / progress["total"]) * 100
                print(f"\rä¸Šä¼ è¿›åº¦: {percent:.2f}%", end="", flush=True)
        return idx

    @validate_call
    def _upload_file_multi(
        self,
        local_filename: str,
        upload_path: str,
        isdir: Literal[0, 1] = 0,
        rtype: Literal[1, 2, 3] = 1,
        max_workers: Optional[int] = None,
        bs: Literal[4, 16, 32] = 4,
        show_progress: bool = True,
    ) -> None | dict:
        """
        ä½¿ç”¨å¤šçº¿ç¨‹æ–¹å¼å°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°ç™¾åº¦ç½‘ç›˜.
        """
        if self.userinfo is None:
            block_size=4
        elif self.userinfo.viptype == 1:
            block_size=16
        elif self.userinfo.viptype == 2:
            block_size=32
        else:
            block_size=4
        block_size = block_size * 1024 * 1024  # Convert MB to bytes

        file_path = Path(local_filename)
        file_size = file_path.stat().st_size

        content_md5 = calculate_md5(file_path)  # æ–‡ä»¶MD5ï¼Œ32ä½å°å†™
        slice_md5 = calculate_slice_md5(file_path)  # æ–‡ä»¶å‰256KBçš„MD5
        block_list = get_file_md5_blocks(file_path, block_size=block_size)

        # é¢„åˆ›å»ºæ–‡ä»¶
        res1 = self.up.precreate(
            path=upload_path,
            size=file_size,
            isdir=isdir,
            block_list=block_list,
            rtype=rtype,
            content_md5=content_md5,
            slice_md5=slice_md5,
        )
        if not res1 or res1.get("errno") != 0:
            print(f"é¢„åˆ›å»ºå¤±è´¥: {res1}")
            return
        uploadid = res1["uploadid"]
        # è·å–ä¸Šä¼ åœ°å€
        res2 = self.up.locateupload(
            path=upload_path,
            uploadid=uploadid,
        )

        if not res2 or not res2.get("servers"):
            print(f"è·å–ä¸Šä¼ åœ°å€å¤±è´¥: {res2}")
            return
        server_url = res2["servers"][0]["server"]

        # å¤šçº¿ç¨‹ä¸Šä¼ åˆ†ç‰‡
        # è®¡ç®—å¯ç”¨çš„çº¿ç¨‹æ•°
        m = os.cpu_count() or 1
        max_workers = m - 1 if max_workers is None else max_workers
        max_workers = min(max_workers, len(block_list))
        # print(f"å¼€å§‹å¤šçº¿ç¨‹ä¸Šä¼ åˆ†ç‰‡, çº¿ç¨‹æ•°: {max_workers}")
        progress: dict = {"uploaded": 0, "total": len(block_list), "lock": Lock()}
        with file_path.open("rb") as f:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                for idx, expected_md5 in enumerate(block_list):
                    f.seek(idx * block_size)
                    chunk = f.read(block_size)
                    if not chunk:
                        break  # æ–‡ä»¶è¯»å–å®Œæ¯•
                    future = executor.submit(
                        self.upload_part,
                        server_url,
                        upload_path,
                        uploadid,
                        idx,
                        chunk,
                        expected_md5,
                        progress,
                        show_progress,
                    )
                    futures.append(future)

                for future in as_completed(futures):
                    try:
                        idx = future.result()
                    except Exception as e:
                        print(f"\nåˆ†ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
                        return

        # åˆ›å»ºæ–‡ä»¶
        res3 = self.up.create(
            path=str(upload_path),
            size=str(file_size),
            isdir="0" if isdir == 0 else "1",
            block_list=json.dumps(block_list, separators=(",", ":")),
            uploadid=str(uploadid),
            rtype=rtype,
        )
        print("\nâœ… æ‰€æœ‰åˆ†ç‰‡ä¸Šä¼ å®Œæˆ")
        return res3

    @validate_call
    def _upload_file_loop(
        self,
        local_filename: str,
        upload_path: str,
        isdir: Literal[0, 1] = 0,
        rtype: Literal[1, 2, 3] = 1,
        max_workers: Optional[int] = None,
        bs: Literal[4, 16, 32] = 32,
        show_progress: bool = True,
    ) -> None | dict:
        """
        ä½¿ç”¨å¤šçº¿ç¨‹æ–¹å¼å°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°ç™¾åº¦ç½‘ç›˜.
        """
        block_size = 4 * 1024 * 1024  # 4MB

        file_path = Path(local_filename)
        file_size = file_path.stat().st_size

        content_md5 = calculate_md5(file_path)  # æ–‡ä»¶MD5ï¼Œ32ä½å°å†™
        slice_md5 = calculate_slice_md5(file_path)  # æ–‡ä»¶å‰256KBçš„MD5
        block_list = get_file_md5_blocks(file_path, block_size=block_size)

        # é¢„åˆ›å»ºæ–‡ä»¶
        res1 = self.up.precreate(
            path=upload_path,
            size=file_size,
            isdir=isdir,
            block_list=block_list,
            rtype=rtype,
            content_md5=content_md5,
            slice_md5=slice_md5,
        )
        if not res1 or res1.get("errno") != 0:
            print(f"é¢„åˆ›å»ºå¤±è´¥: {res1}")
            return
        uploadid = res1["uploadid"]
        # è·å–ä¸Šä¼ åœ°å€
        res2 = self.up.locateupload(
            path=upload_path,
            uploadid=uploadid,
        )

        if not res2 or not res2.get("servers"):
            print(f"è·å–ä¸Šä¼ åœ°å€å¤±è´¥: {res2}")
            return
        server_url = res2["servers"][0]["server"]
        # å¾ªç¯ä¸Šä¼ åˆ†ç‰‡
        progress: dict = {"uploaded": 0, "total": len(block_list), "lock": Lock()}
        with file_path.open("rb") as f:
            for idx, expected_md5 in enumerate(block_list):
                f.seek(idx * block_size)
                chunk = f.read(block_size)
                if not chunk:
                    break  # æ–‡ä»¶è¯»å–å®Œæ¯•
                try:
                    self.upload_part(
                        server_url,
                        upload_path,
                        uploadid,
                        idx,
                        chunk,
                        expected_md5,
                        progress,
                        show_progress,
                    )
                except Exception as e:
                    print(f"\n{local_filename}åˆ†ç‰‡ä¸Šä¼ å¤±è´¥: {e}")
                    return
        # åˆ›å»ºæ–‡ä»¶
        res3 = self.up.create(
            path=str(upload_path),
            size=str(file_size),
            isdir="0" if isdir == 0 else "1",
            block_list=json.dumps(block_list, separators=(",", ":")),
            uploadid=str(uploadid),
            rtype=rtype,
        )
        print(f"\nâœ… {local_filename} ä¸Šä¼ å®Œæˆ")
        return res3

    @validate_call
    def upload_folder(
        self,
        local_folder: str,
        upload_path: str,
        rtype: Literal[1, 2, 3] = 1,
        file_max_workers: Optional[int] = None,
        chunk_max_workers: Optional[int] = None,
        bs: Literal[4, 16, 32] = 4,
        show_progress: bool = False,
        exclude_patterns: Optional[list[str]] = None,
    ) -> dict[str, Any]:
        """
        é€’å½’ä¸Šä¼ æœ¬åœ°æ–‡ä»¶å¤¹åˆ°ç™¾åº¦ç½‘ç›˜(ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘ä¸Šä¼ å¤šä¸ªæ–‡ä»¶).

        Args:
            local_folder (str): æœ¬åœ°æ–‡ä»¶å¤¹çš„è·¯å¾„.
            upload_path (str): æ–‡ä»¶å¤¹åœ¨ç½‘ç›˜ä¸­çš„ç›®æ ‡è·¯å¾„.
            rtype (Literal[1, 2, 3]): æ–‡ä»¶å‘½åç­–ç•¥, é»˜è®¤ä¸º 1.
                1: å½“pathå†²çªæ—¶, è¿›è¡Œé‡å‘½å
                2: å½“pathå†²çªä¸”block_listä¸åŒæ—¶, è¿›è¡Œé‡å‘½å
                3: å½“äº‘ç«¯å­˜åœ¨åŒåæ–‡ä»¶æ—¶, å¯¹è¯¥æ–‡ä»¶è¿›è¡Œè¦†ç›–
            file_max_workers (int): æ–‡ä»¶çº§å¹¶å‘çº¿ç¨‹æ•°, é»˜è®¤ä¸º CPUæ ¸å¿ƒæ•°-1.
            chunk_max_workers (int): å•ä¸ªæ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ çš„æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°, é»˜è®¤ä¸º CPUæ ¸å¿ƒæ•°-1.
            bs (Literal[4, 16, 32]): åˆ†ç‰‡å¤§å°, å•ä½ä¸º MB, é»˜è®¤ä¸º 4MB.
            show_progress (bool): æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦, é»˜è®¤ä¸º False.
            exclude_patterns (list[str]): è¦æ’é™¤çš„æ–‡ä»¶/æ–‡ä»¶å¤¹æ¨¡å¼åˆ—è¡¨ï¼Œæ”¯æŒé€šé…ç¬¦ï¼Œå¦‚ ['*.tmp', '__pycache__', '.git']

        Returns:
            dict: åŒ…å«ä¸Šä¼ ç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬æˆåŠŸå’Œå¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨

        Note:
            - ä½¿ç”¨ä¸¤å±‚å¤šçº¿ç¨‹: æ–‡ä»¶çº§å¹¶å‘ + æ¯ä¸ªæ–‡ä»¶å†…éƒ¨çš„åˆ†ç‰‡å¹¶å‘
            - file_max_workers: æ§åˆ¶åŒæ—¶ä¸Šä¼ å¤šå°‘ä¸ªæ–‡ä»¶
            - chunk_max_workers: æ§åˆ¶æ¯ä¸ªæ–‡ä»¶å†…éƒ¨åŒæ—¶ä¸Šä¼ å¤šå°‘ä¸ªåˆ†ç‰‡

        Example:
            ```python
            from cpanbaidu import PanBaiduOpenAPI

            cpan = PanBaiduOpenAPI()
            result = cpan.upload.upload_folder(
                local_folder="./my_project",
                upload_path="/apps/cpanbaidu/my_project",
                file_max_workers=3,  # åŒæ—¶ä¸Šä¼ 3ä¸ªæ–‡ä»¶
                chunk_max_workers=4,  # æ¯ä¸ªæ–‡ä»¶ä½¿ç”¨4ä¸ªçº¿ç¨‹ä¸Šä¼ åˆ†ç‰‡
                exclude_patterns=['*.pyc', '__pycache__', '.git', 'node_modules']
            )
            print(f"æˆåŠŸä¸Šä¼ : {result['success_count']} ä¸ªæ–‡ä»¶")
            print(f"å¤±è´¥: {result['failed_count']} ä¸ªæ–‡ä»¶")
            ```
        """
        from fnmatch import fnmatch

        folder_path = Path(local_folder)
        if not folder_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {local_folder}")
        if not folder_path.is_dir():
            raise ValueError(f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {local_folder}")

        # é»˜è®¤æ’é™¤æ¨¡å¼
        if exclude_patterns is None:
            exclude_patterns = []

        # æ”¶é›†æ‰€æœ‰éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶
        files_to_upload = []

        def should_exclude(path: Path) -> bool:
            """æ£€æŸ¥è·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤"""
            for pattern in exclude_patterns:
                # æ£€æŸ¥æ–‡ä»¶åæˆ–ç›¸å¯¹è·¯å¾„æ˜¯å¦åŒ¹é…æ¨¡å¼
                if fnmatch(path.name, pattern):
                    return True
                # æ£€æŸ¥å®Œæ•´ç›¸å¯¹è·¯å¾„
                try:
                    rel_path = path.relative_to(folder_path)
                    for part in rel_path.parts:
                        if fnmatch(part, pattern):
                            return True
                except ValueError:
                    pass
            return False

        for item in folder_path.rglob("*"):
            if item.is_file() and not should_exclude(item):
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                rel_path = item.relative_to(folder_path)
                # æ„å»ºç½‘ç›˜è·¯å¾„
                remote_path = f"{upload_path.rstrip('/')}/{rel_path.as_posix()}"
                files_to_upload.append((str(item), remote_path))

        total_files = len(files_to_upload)
        if total_files == 0:
            return {
                "success": [],
                "failed": [],
                "success_count": 0,
                "failed_count": 0,
                "total": 0,
            }

        # ä¸Šä¼ ç»“æœç»Ÿè®¡
        results = {
            "success": [],
            "failed": [],
            "success_count": 0,
            "failed_count": 0,
            "total": total_files,
        }

        # è®¡ç®—æ–‡ä»¶çº§å¹¶å‘æ•°
        m = os.cpu_count() or 1
        file_max_workers = m - 1 if file_max_workers is None else file_max_workers
        file_max_workers = min(file_max_workers, total_files)

        # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤ç»“æœç»Ÿè®¡
        results_lock = Lock()

        def upload_single_file(idx: int, local_file: str, remote_file: str):
            """ä¸Šä¼ å•ä¸ªæ–‡ä»¶çš„è¾…åŠ©å‡½æ•°"""
            file_name = Path(local_file).name
            try:
                # å¼€å§‹ä¸Šä¼ ï¼ˆä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œé¿å…å¤šçº¿ç¨‹æ··ä¹±ï¼‰
                result = self._upload_file_loop(
                    local_filename=local_file,
                    upload_path=remote_file,
                    isdir=0,
                    rtype=rtype,
                    max_workers=chunk_max_workers,  # æ¯ä¸ªæ–‡ä»¶å†…éƒ¨çš„åˆ†ç‰‡ä¸Šä¼ çº¿ç¨‹æ•°
                    bs=bs,
                    show_progress=False,  # å…³é—­å•ä¸ªæ–‡ä»¶çš„è¿›åº¦æ˜¾ç¤º
                )

                with results_lock:
                    if result:
                        results["success"].append(
                            {
                                "local_path": local_file,
                                "remote_path": remote_file,
                                "result": result,
                            }
                        )
                        results["success_count"] += 1
                        if show_progress:
                            # åªåœ¨å®Œæˆæ—¶è¾“å‡ºä¸€è¡Œ
                            print(f"âœ… [{results['success_count'] + results['failed_count']}/{total_files}] {file_name}")
                    else:
                        results["failed"].append(
                            {
                                "local_path": local_file,
                                "remote_path": remote_file,
                                "error": "ä¸Šä¼ è¿”å›None",
                            }
                        )
                        results["failed_count"] += 1
                        if show_progress:
                            print(f"âŒ [{results['success_count'] + results['failed_count']}/{total_files}] {file_name} (è¿”å›None)")

            except Exception as e:
                with results_lock:
                    results["failed"].append(
                        {
                            "local_path": local_file,
                            "remote_path": remote_file,
                            "error": str(e),
                        }
                    )
                    results["failed_count"] += 1
                    if show_progress:
                        error_msg = str(e)[:50]  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                        print(f"âŒ [{results['success_count'] + results['failed_count']}/{total_files}] {file_name} ({error_msg})")

        # ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘ä¸Šä¼ æ–‡ä»¶
        print(f"ğŸš€ å¼€å§‹å¤šçº¿ç¨‹ä¸Šä¼ , æ–‡ä»¶å¹¶å‘æ•°: {file_max_workers}")
        with ThreadPoolExecutor(max_workers=file_max_workers) as executor:
            futures = []
            for idx, (local_file, remote_file) in enumerate(files_to_upload, 1):
                future = executor.submit(upload_single_file, idx, local_file, remote_file)
                futures.append(future)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    if show_progress:
                        print(f"âŒ æ–‡ä»¶ä¸Šä¼ ä»»åŠ¡å¼‚å¸¸: {e}")

        # æ‰“å°æ€»ç»“
        print(f"\n{'=' * 60}")
        print("ğŸ“ˆ ä¸Šä¼ å®Œæˆç»Ÿè®¡:")
        print(f"   âœ… æˆåŠŸ: {results['success_count']} ä¸ªæ–‡ä»¶")
        print(f"   âŒ å¤±è´¥: {results['failed_count']} ä¸ªæ–‡ä»¶")
        print(f"   ğŸ“Š æ€»è®¡: {results['total']} ä¸ªæ–‡ä»¶")
        print(f"{'=' * 60}")

        # å¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œæ˜¾ç¤ºè¯¦æƒ…
        if results["failed_count"] > 0:
            print("\nâŒ å¤±è´¥çš„æ–‡ä»¶:")
            for item in results["failed"]:
                print(f"   - {item['local_path']}: {item['error']}")
        results["errno"] = 0
        return results

    # ä¸Šä¼ å•ä¸ªæ–‡ä»¶é‡‡ç”¨å¤šçº¿ç¨‹
    @validate_call
    def upload_file(
        self,
        local_filename: str,
        upload_path: str,
        isdir: Literal[0, 1] = 0,
        rtype: Literal[1, 2, 3] = 1,
        max_workers: Optional[int] = None,
        bs: Literal[4, 16, 32] = 4,
        show_progress: bool = True,
    ) -> None | dict:
        """
        ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°ç™¾åº¦ç½‘ç›˜ï¼Œé‡‡ç”¨å¤šçº¿ç¨‹åˆ†ç‰‡ä¸Šä¼ æ–¹å¼.

        Args:
            local_filename (str): æœ¬åœ°æ–‡ä»¶çš„è·¯å¾„.
            upload_path (str): æ–‡ä»¶åœ¨ç½‘ç›˜ä¸­çš„ç›®æ ‡è·¯å¾„.
            isdir (Literal[0, 1]): æ˜¯å¦ä¸ºç›®å½•ï¼Œé»˜è®¤ä¸º 0ï¼ˆæ–‡ä»¶ï¼‰.
            rtype (Literal[1, 2, 3]): æ–‡ä»¶å‘½åç­–ç•¥ï¼Œé»˜è®¤ä¸º 1.
                1: å½“pathå†²çªæ—¶, è¿›è¡Œé‡å‘½å
                2: å½“pathå†²çªä¸”block_listä¸åŒæ—¶, è¿›è¡Œé‡å‘½å
                3: å½“äº‘ç«¯å­˜åœ¨åŒåæ–‡ä»¶æ—¶, å¯¹è¯¥æ–‡ä»¶è¿›è¡Œè¦†ç›–
            max_workers (int): åˆ†ç‰‡ä¸Šä¼ çš„æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º CPUæ ¸å¿ƒæ•°-1.
            bs (Literal[4, 16, 32]): åˆ†ç‰‡å¤§å°ï¼Œå•ä½ä¸º MBï¼Œé»˜è®¤ä¸º 4MB.
            show_progress (bool): æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦ï¼Œé»˜è®¤ä¸º True.

        Returns:
            dict: åŒ…å«ä¸Šä¼ ç»“æœçš„å­—å…¸
        """
        return self._upload_file_multi(
            local_filename=local_filename,
            upload_path=upload_path,
            isdir=isdir,
            rtype=rtype,
            max_workers=max_workers,
            bs=bs,
            show_progress=show_progress,
        )
